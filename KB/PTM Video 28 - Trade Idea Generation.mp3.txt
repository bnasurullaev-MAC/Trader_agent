Okay, so welcome to video number 28.

We are going to look at now as part of the trade idea generation process,

we're going to look at data mining and processing mistakes and solutions.

So far, we have gone through the quantitative process and we've looked at

long ideas and short ideas and also turnarounds, X growth names and value traps.

What we've done is we've gone through forward-looking metrics, our identification process,

and we've gone through an evidence process,

looking at backwards-looking quantitative data as well.

What we're going to be looking at here in this video

is data mining and processing mistakes

and some solutions for the forward-looking quantitative identification process.

What we're trying to achieve here is that we want to get our quantitative spreadsheet work

to reflect the reality of a sector as closely as possible. How can we even make sensible conclusions to determine whether there's

genuine positive and negative outliers in a sector and analyze everything else

in between if we don't know for certain that the data that we've downloaded, the

sector data that we're looking at accurately reflects

reality. Now what's interesting is that ITPM teaching methods went globally

public in 2013 and over a number of years we witnessed and noticed some

patterns that emerged, patterns of behavior that emerged amongst retail traders

at ITPM when they were doing their quantitative processing.

Most commonly, what we saw were patterns

where people were making some basic errors

in their quantitative processing identification phase.

So what we're going to do here is feed back this information to you so you just simply don't make

these mistakes and you erase them immediately. So you save yourself a ton of time in the identification phase of the quantitative processing.

It's really important that when you start this that you get off on the right foot and you eliminate all of the common errors

that we've witnessed, that we've seen over the last decade.

And what it really comes down to is a lack of attention to detail

and just some really basic common sense.

And unfortunately, trading is not an easy pursuit.

It does require a lot of attention to detail and common sense.

But from a teaching perspective, from an ITPM perspective, we have to be very, very careful here

because there is always a catch-22 when teaching people from scratch how to trade. Because if you want to become, or anybody

wants to become, a successful trader over their lifetime or career, you have to become self-sustainable.

You have to be able to only rely on yourself.

In addition, you have to have a very strong work ethic and you have to have the ability to be able to work smart and not hard.

So not going down endless rabbit holes to get to information that's irrelevant.

Working smart is important. So if you recall the four principles of ITPM,

self-sustainability, work ethic, free information, and working smart, not hard.

There's very good reasons why we have these principles. It's because we've been in this game for a very long time. And we know what traits are required

to produce consistently profitable traders.

And part of self-sustainability, work ethic,

and the ability to work smart, not hard,

is the ability to be able to process and understand large amounts of data.

And guess what? That requires a lot of attention to detail. On top of that, you have to have the

ability to interpret the data, and that requires common sense. And the only way that you're going to acquire this skill

set or these skill sets and be good at implementing these principles over your career, over your

lifetime, is if you do the work yourself and find the answers yourself. Good traders find the answers themselves.

So the catch 22 here from a teaching perspective is that we want to give you

all the information that enables you to be successful in

trading. But we know at the same time that to be successful in trading, you have to do it yourself.

So I guess the best analogy I can give here is that we can provide you the golden keys to the

golden door that opens to the golden kingdom. But you have to open the door yourself and walk over the threshold.

So from a teaching perspective, we have to draw a line in the sand that we simply do not cross.

Because if we did the opposite and we told you all the time exactly what to do and what to buy, what to sell, when to buy it, when to sell it,

etc., etc. You simply would never become a good trader. You wouldn't be self-sustainable.

You wouldn't have a solid work ethic. You wouldn't have the ability to work smart and not hard.

And you wouldn't have attention to detail and common sense. We would just

be doing you a massive disservice. So when it comes to data processing mistakes, we're going to

point you in the right direction. But of course, you have to then go off and do all of the work yourself to generate your own trade ideas.

So the first step is to eliminate all of the common mistakes that people make in the beginning when they have very little attention to detail and common sense.

and common sense. Now the good news is, is that the more you practice processing and analyzing big data sets and interpreting them, the more attention to detail and common sense

you're going to get. And this will actually help you outside of trading as well, just in the general world, in everyday life.

You will become generally just a lot sharper and you'll be able to spot discrepancies and potential opportunities,

not just in trading, but even outside trading as well. You will just become better at self-sustainability,

your work ethic, working smart, not hard, and have much better attention to detail

and common sense the more you engage in the systematic trade idea generation

process and the quantitative process at the identification stage. So when you're

going through your monthly processes, you're going to be downloading data. Now this data

ITPM does provide you with updates of the US stock screener sheet that we've looked at previously

in the PTM video series that is downloaded from Zaxx. It's available on a monthly basis

in the ITPM data section on the website. And this data is a NAICS classification data that's updated every month.

And it is available publicly.

You can download it yourself.

It's accessible and downloadable by everybody.

However, you do need to learn how to organize the data and process it correctly with attention

to detail and common sense.

and process it correctly with attention to detail and common sense.

Additionally, data sources can of course change over time and in the future.

You have to learn how to search for data sets using search engines like Google and not just rely on people to tell you where to find it and do all of the work for you. So by now, you should know

that this is not how the Institute of Trading and Portfolio Management works. You will never be a

consistently profitable trader if you constantly rely on people to tell you what to do, where to get

information that's important, and then they literally do the work for you.

It's impossible for you to become a consistently profitable trader if that's the route you take.

So you have to learn to look for this data yourself and rely on yourself and also learn how to process it correctly.

also learn how to process it correctly. So you can process correctly by yourself with no help from anybody on a regular monthly basis.

Now, here's our first problem with big data sets and downloading big data sets from third party sources.

It's trusting that all the numbers are correct and accurate. So when visiting websites

like Zaxx or Nasdaq.com and downloading the forward-looking data for around 2200 plus

stocks, there's a major problem with doing so. You're engaging in an exercise of a large-scale data dump and you will be downloading

data with differing labels from the ones you are used to in the PTM video series.

There will be different titles for the columns in the spreadsheet when you download it and you have to organize the data into a recognizable and easy to use format similar to

the way we have done it or exactly the same as the way we have done it with our 11 numbers.

So we have stock price, market capitalization,

Earnings per share zero, which is last year's reported EPS.

EPS one, which is forward looking EPS of the current year.

EPS two, forward looking EPS of next year.

Earnings growth one, earnings growth two, PE one, PE two, PEG one and PEG two.

These are the standard 11 numbers that we want to get in any download to reflect reality for each individual stock in a sector and of course, therefore, the sector as a whole.

And when you initially download spreadsheets like the ones from Zacks or Nasdaq.com, these titles will not be there. You have to

rearrange it and organize the sheet to get it all accurate and correct. So that's the first step.

But this creates also a bigger problem in terms of the big data dump. Large data dumps,

when we are downloading them, if we're not doing any work whatsoever on the numbers, we are making the assumption that every number in all rows, columns and cells for 2200 plus stocks is 100% accurate.

As traders, we have to have attention to detail and common sense, and and fixing the errors to ensure an accurate reflection of reality. And that is attention to detail. On top of that, having

common sense to enable sensible conclusions about the sector. What's happening here, if you download a big data spreadsheet from a

third-party source, if you're doing absolutely nothing to cleanse the data, what you're doing

is you're trusting a paste special data dump from a third-party source and you're trusting that the numbers are a

hundred percent accurate. By not checking and fixing any issues with the data, the

numbers that you're basing your decisions on to identify both positive and

negative outliers and of course everything in between could just be

totally incorrect. So your conclusions could just be totally incorrect.

So your conclusions will just be meaningless and wrong.

So how can we even begin to consider taking real money positions with real money in a trading account

if we don't even know if our ideas, our trade ideas, reflect reality.

We have to get the data of a chosen sector to reflect reality as closely as possible.

And we have to have total confidence in the data and our findings.

Now, the good news is, is out of our 11 numbers that we organize our spreadsheets into as part of the identification process, as long as you can get the stock price and the EPS numbers or estimates accurate, all the other data can just be worked out using Excel formulas.

So when we're working out, for example, PE, it's just the stock price over the EPS.

So if you get the stock price right and you get the EPS estimates right, you're going to get PE correct.

The earnings growth numbers, they are just percentage differences from one EPS number to another EPS number. If you get the percentages right, you're going to get earnings growth percentage

right. For PEG ratio, it's just PE divided by the earnings growth percentage. So if you get

the stock price right and the EPS right and you've calculated PE and the

earnings growth number correctly, you're going to get the PEG number right.

So everything goes back to just getting the stock price and the EPS estimates accurate.

So something that you're going to find that happens when you download spreadsheets from third party data sources,

and in particular with the Zaxx or nasdaq.com download,

you're going to find that the cells

in the spreadsheet are not live.

So we have a solution for that. It's very

straightforward. We make the cells live and we eliminate any rogue cells. So please

when you download a spreadsheet from a third-party data source,

just eyeball the goddamn numbers.

Don't blindly go through a spreadsheet and not eyeball it and see just on a basic cursory

eyeballing if the numbers look right.

So eyeball the numbers and just see if they make sense.

Have attention to detail, please.

When you just do a cursory, non-thorough eyeballing, so without really going into

great detail, you may find that some of the numbers don't make sense.

sense. Most of the time this is because you've downloaded a spreadsheet from a

third-party data source that is big data and the cells are not live. We have to

make them live and make the numbers as accurate as possible. So if we look at

this sector here for example, in the first step, when we've downloaded the

spreadsheet, we've downloaded the data and we're drilling down into a particular sector.

So for example, like this sector, apparel manufacturing, the first thing we would do

is just eyeball the sector. And because we've got a decent level of attention to detail, we're going to find

potentially rogue cells. And here in this sector, just by eyeballing the data, we can see that

something is wrong with EPS1 or EG1 for Capri Holdings. So we can see that last

year's EPS of $3.89 cents, it's in the spreadsheet as falling to $1.50. But the

earnings growth is negative 27.89%. But how can it be? EPS dropping from $3.89 to $1.50 is not

losing 27.89% of your earnings. It's not negative 27.89% It's actually negative 61.43. So in this situation, and this can happen and be very common,

it can happen a lot because we're dealing with 2200 plus stocks in a big data download from a

third-party source that doesn't have live cells. In this particular situation,

either the EPS estimate is wrong

or the paste special of whoever has put

this spreadsheet together has failed

and has corrupted the EG1 cell.

So how do we actually go about fixing this?

Well, it's very easy and straightforward.

Remember, as long as you can get the stock price

and EPS numbers accurate,

all other data can be worked out just using Excel formulas.

So we make the cells live.

So we go off and we just do a very quick

and simple investigation. We check the EPS estimates

from publicly available sources and add in the stock price to the spreadsheet

in order to make all of our cells live.

And here, for this example, we've just used Yahoo Finance.

There will, of course, be always multiple other free sources.

Just start Googling and stop crying.

Do the work.

Now here, we realize the problem in the spreadsheet,

because we have $3.89 in Yahoo Finance for last year's EPS,

we realize the problem in the spreadsheet must be with the earnings growth number being corrupted in some way.

So according to Yahoo Finance, we have $3.89 for EPS a year ago,

We have $3.89 for EPS a year ago, and we have an average consensus estimate from analysts for the current year of $1.50. So we know our estimates in the spreadsheet for earnings per share are actually

correct. So whoever's put this spreadsheet together on the other side at our third

party that we're downloading the data from, they have got the EPS estimates correct in the spreadsheet,

but the percentage number for EG1 is off. So what do we do about it? Do we cry about it?

Do we cry about it? Do we send emails to ITPM asking if there's any other data sources?

Do we go down to the local bar and start asking our friends how to find data online?

Do we go on internet forums, create threads, hoping and praying that somebody is going to come to our rescue

to help us organize our data properly. Do we post things on social media about ITPM being

an education company that doesn't provide you with shortcuts to become multimillionaires

or do we just give up?

Well, of course not.

We just do the work.

So we add in the stock price data for Capri Holdings,

and we make all the sales live.

And then we repeat it for every stock in the sector.

So you can see here in the first screenshot at the top

of the screen we've got the percentage calculation formula for EG1 and we make that cell live,

negative 61.5%. This is possible because we have the stock price and we have the right EPS data.

Then we move on to the other cells for Capri Holdings. We work out the PE

ratios. That's the next screenshot below in the middle. We work out

the PE ratios for period one and period two. And then in the bottom screenshot, we work out

the PEG ratios for period one and period two. That's for Capri Holdings. And then we do it

for the rest of the sector as well. And of course, in Excel, there are shortcuts to working out numbers quickly, but we want to make sure that

we have attention to detail to make sure that if we use shortcuts, the numbers are still coming out

accurately. So all cells for Capri Holdings are then made live and then you can auto fill down but where

there are negative or positive minorities you're going to have to

overwrite the formulas. We will come on to this processing mistake in a moment

but what you've just seen here every time you're going through the process of

generating a trade idea you're going to have to do every time you're going through the process of generating a trade

idea, you're going to have to do this.

You're going to have to make live cells and eliminate rogue cells.

It's the first step to making sure that your sector reflects reality as closely as possible

and all your cells are actually correct and accurate.

Now, there is a mistake that some people make at this stage.

They think that they have to do this for all 2200 plus stocks every month, all the time.

You don't. Don't try to make the numbers of the 2200 plus stocks

live in the spreadsheet and check all of them. It's way too much work. This is not working smart.

This is working too hard. You're going down huge, endless rabbit holes. So do it when you have drilled down to less than 20 or

so stocks. Use your time wisely and work smart not hard.

Now something else that falls under attention to detail is company's financial

year ends. You have to make sure that the data lines up for a particular

company's financial year end. So in this sector of nine stocks for example, two of

them have their financial year end in March and another two of them have their

financial year end at the end of January. Now this is just down to having a bit of

attention to detail and common sense, thinking about what you're looking at on

the screen. What sector are you looking at? Does it have seasonal factors? Well,

financial year ends change or can

be different across stocks in seasonal sectors. It happens a lot. So this is the apparel manufacturing

sector. And some companies choose to have their financial year end at certain times. So like the

end of March and the end of January, because they make the bulk of their earnings during the holiday

season and in the January after holiday season sales. So whilst you're processing

and checking forward EPS estimates you need to make sure that the right years

line up across the sector. In a big data dump, sometimes the numbers will be off. So whoever's

on the other side at the third-party data source, they may have put the wrong EPS for the wrong

financial year in a cell. So for example, the EPS number from two years ago might be last year's number.

And last year's number might be this year's number.

You have to double check it and get it right.

Be accurate with your financial year ends and get it correct.

Now, one of the biggest errors we see is actually using common sense to understand positive and negative EPS. So changes when companies go from positive to negative EPS and changes when companies go from negative to positive

EPS. So this creates a problem in big data dumps because whoever's on the other side has

done paste special across 2200 plus stocks and the data can end up being

spurious and not make common sense. So in our example you will notice from the

initial data download that PVHCorp and Under Armour have negative,

so loss-making EPS for last year in year zero.

And they have positive EPS in year one.

So they're going from losses to profits from year zero last year to the current year, year one.

So when calculating the earnings growth percentage,

the big data download has simply done an auto-fill

and the numbers are very large

and the calculations are just wrong.

So think of it the other way round round in terms of a positive EPS.

If a stock goes from $1 of earnings to $3 of losses,

how much of the earnings of the

company have they lost in percentage terms? Well, if you did the calculation here in absolute terms,

then they'd be losing $4 in total from an initial position of $1. So they'd be losing 400% of their earnings. But how can a company lose 400% of their earnings? They

can't. A company can only lose 100% of their earnings. On the flip side, if we're going

from a loss-making operation to a profit-making position.

You can't recover 400% of your losses.

You can only recover 100% of your losses.

You need to overwrite these cells with the number 100 for 100%. So loss-making to profit in this case plus positive 100%. And for

operations that are going from a profit-making position to losses, you

have to overwrite the sell with negative 100 minus 100%. So when you're

going through your quantitative processing for a sector and you're

cleaning up all the data, making the cells live, you have to watch out for this situation.

You have to overwrite the cells manually that previously had a formula in and overwrite them

for either positive 100 or negative 100.

Now something else that creates a problem when it comes to attention to detail and

common sense in the quantitative process is the law of small numbers. So when you

download big data dumps that work out earnings growth percentages that are based on EPS,

you're going to find quite often very wild earnings growth percentage numbers.

So numbers like 500%, 1000%, 5000%, etc.

percent, five thousand percent, etc. And this can just be because a company is going from a very small EPS number to another number that's just large. So, for example, if a company last year

had one cent of earnings, but this year has 10 cents of earnings. They're going to be in the downloaded spreadsheet

calculated on an auto-fill with a paste special as having 900% earnings growth. Now, if we

using some common sense here, does this mean that we should automatically deduce that this company

is the positive outlier in the sector? Of course not. We've got to use common sense here. Look at

the company's EPS in more detail. So for example, like the last two, three or five years. The company may even be a revenue growth

story or they may have actually made 12 cents in EPS two years ago. Meaning the

10 cents that we've got for the current year looking forward, they haven't recovered back this year versus two years ago back

to 12 cents of earnings. So it could be the worst stock in the sector.

You have to use common sense here. Don't just blindly follow the process. Think at every stage about what you're looking at.

So for example, if we are eyeballing,

having attention to detail and some common sense,

when we're looking at our example here on the screen,

we would notice very quickly if we looked at,

for example, Levi Strauss, that they have 433% earnings growth for EG1 and that is a

move of EPS going from 21 cents to a dollar and 12 cents. And we can also see a big number, for example, for G3 Apparel at 333% for EG1.

And that is EPS going from 55 cents to $2.39. So not only do we have a problem in our example sector here,

only do we have a problem in our example sector here where we have for PVHCorp and Under Armour going from losses to profits and we have to overwrite the sales manually for 100%, we also

potentially have a problem here in the sector when we're doing our quantitative processing of the laws of small numbers. So

percentage changes based on EPS coming from a low number, a small number, and moving to a higher

number, creating very high percentages that could ultimately flatter the reality of those stocks.

ultimately flatter the reality of those stocks. And this could have an outsized impact on our interpretation and meaning of what's actually going on for these stocks and in the sector. Which brings us on

to our next issue, which is contributions to the mean. So contributions to the sector averages.

So once you have actually cleansed your data and you're very confident that all of the live cells

and all of the numbers have been attained as accurate, so the stock price and EPS numbers

and all of your formulas are correct.

Once you've actually cleansed your data, you're going to then start to attempt at making some

sensible deductions about forward-looking valuation in order to identify positive and negative outliers and everything in between.

And of course, what we want to be doing here is identifying genuine positive and negative outliers.

So in our example here, we've worked out the mean values for earnings growth 1, earnings growth 2,

for earnings growth 1, earnings growth 2, PE1, PE2, PEG1 and PEG2, the mean values for the sector.

And we've done that by dividing by the amount of stocks in the sector. So we're dividing by nine.

Now, when we look at the earnings growth number for the apparel sector for EG1, we have to ask ourselves a sensible

question. Is it sensible to assume that in the apparel manufacturing sector that

117% earnings growth is a real average for the whole sector? Well, common sense would tell us no.

When we look at the contributions of each stock to the mean number, obviously,

Levi Strauss and G3 have an outsized contribution relative to other stocks.

relative to other stocks. So the contribution from Levi and G3 is large, and it's skewing the mean and the reality of the sector, and it's creating a scenario that is flattering the earnings growth

of the overall sector. So why is this actually important? Well, in your processing, you may actually miss a positive

outlier and potentially a really great long idea because the averages are just skewed.

And you may make the mistake of thinking that Levi Strauss and G3, because they just have much higher percentage earnings growth versus the sector average,

that these are the positive outliers. They may be, they may not be, but at this stage,

we have to understand that they're having an outsized contribution to

the mean relative to other stocks in the sector and that could be flattering the overall sector

in terms of earnings growth and leading us down the wrong path to make incorrect deductions and

interpretations of what's going on with the sector and all the stocks in the sector.

and all the stocks in the sector. So what can we do about this? Well, we can stress test the stocks and have a look at calculating their contributions to the mean and get a better understanding of what

happens when we eliminate these stocks to the sector itself and our own interpretation and deductions of what's going on in the rest of the sector without Levi Strauss and G3 in the sector.

cells and type a zero in them. And instead of dividing by nine, we can just divide by seven to check their contributions to the mean. And here we discover that Levi Strauss and G3

contribute around 75% to the 117% earnings growth one number because when we eliminate them we are left with an average of 41.38%.

And we can do something else as well. If we repeat the exercise but only with Levi's eliminated

and we divide by eight we get an earnings growth one number for the mean of 78%, meaning Levi's contributes 39%

to the 117% sector average,

and G3 around 36% to the sector average.

So again, we have to use some common sense here. The earnings growth

two number when we look another year forward is 50% which we would probably consider a more

normal but still high level of earnings growth for this sector. And we take note that the sector for the previous financial year is coming out of

problems. So it looks like the sector as a whole is having some sort of turnaround and then return

to normalization. So it looks like pretty much everything is a turnaround play in this sector, except for perhaps stocks like Contour and Hannah's Brands.

So Contour has 40% earnings growth for EG1 and 11% for EG2.

And Hannah's Brands has 11% earnings growth for EG1 and 7.5% for EG2.

And these numbers seem more like sensible or normal earnings growth numbers for a company that's in a sector like apparel manufacturing.

manufacturing. Now you'll notice here that we've also highlighted the Under Armour PE1 at 96.42 and the negative pegs of Capri Holdings and VFC. We'd also need to go through the same exercise

of working out all of their contributions to the mean as well to get

some perspective on what's going on there too. You'll also notice that for the

PEG1s for Levi Strauss and G3 we've also overwritten the PEG1 cells.

We've done this because when we overwrote the earnings growth numbers with zero,

it corrupted those cells. Now, in this particular situation, when we have a scenario like this in a sector like this,

like this, we would look more towards year two for clues on outliers and we would anchor ourselves to an earnings growth rate of 40 to 50%. And we were left with 41.38% earnings growth for the sector

average in EG1. And having made no changes in the column for EG2, we have an earnings growth

number for the sector average, which is 50%.

So over the next couple of years, it seems that 40% to 50% earnings growth

is probably going to be quite normal for this sector.

So what does that leave us with?

It leaves us with Capri Holdings with an earnings growth 2 number of 144%,

Under Armour with an EG2 number of 79% and VFC with an EG2 number of 126%.

So these are starting to look like interesting potential positive outliers.

Additionally, when we look at the PE2 column for the sector,

we see that there's a sector average of 21.5 times earnings.

And when we look at Under Armour,

and VFC, we see that the PE2 for both of those stocks is higher than the sector average.

And when we look at the PE2 for Capri Holdings, we see that comes in lower than the sector average.

when we're not adjusting the PE2 for Under Armour,

which has the highest PE2 in the sector and is obviously making a very large contribution to the overall sector mean.

Now, bear in mind, we haven't even put a market cap filter into our process here yet.

So let's do that now as a useful exercise. put a market cap filter into our process here yet.

So let's do that now as a useful exercise. So we put a market cap filter on

and we're looking for potential long ideas here.

And given that VFC has a market cap of $33 billion,

that VFC has a market cap of $33 billion, this only leaves Capri and Under Armour as potential positive outliers in the sector. However, it is obvious that they are not sequentially positive

earnings growth momentum stocks. It's pretty obvious that they are still

turnarounds. So if you were looking for long ideas in this sector, at this moment in time,

this is how you would have gone through your processing to ensure that you're making no mistakes

and you're actually going through the processing with the correct data

and asking obvious questions along the way

and making sensible, common-sense interpretations of the data.

common sense interpretations of the data.

And then, of course, if you think you've identified what are potential positive outliers or even negative outliers,

you would then go off and do the work to find out what is behind the earnings growth numbers. What is behind the valuation?

What is driving the EPS? What is driving the earnings growth? What is driving the valuation premium or discount? Remember, there is always a reason why something trades on a premium or a discount. So now

we move from the identification phase and we go on to the evidential, the

evidence phase. So as you can see in order for

us to make sensible conclusions with meaning when we're going through the quantitative process.

We can't make the mistakes. We've got to get the data right. We've got to get our spreadsheets

clean and correct and accurate. And we have to have attention to detail in order to do that and we have

to have common sense to make sensible interpretations.

Another mistake that we see is not so much a processing data mistake, more of a market knowledge and common sense mistake or misunderstanding.

So when analyzing a sector, we mentioned earlier that it's important to get the right EPS numbers

or the correct financial years for each stock in the correct cells so everything lines up correctly. And in

our example, Capri Holdings and VFC both had their financial year end on March 31st.

So what this means is that the year two for these stocks is further out by one quarter relative to the other stocks

in the sector. The rest of the sector is going to report their Q4 numbers and full year results

in either January or February 2022. And Capri and VFC are going to report their 2021 full year numbers in April or May

2022. So it's important to do this and understand this because as we get further and further through

a financial year and the market gets more visibility on

revenue and earnings for that year and for the company versus forward-looking

estimates that are existing out there in the market, the probability of a surprise

that's either negative or positive just simply becomes less and less. So for most sectors

and because most stocks have a financial year that ends on December 31st, by Q4 of a company's

financial year, they've already reported three quarters of revenue and earnings data and all the balance sheet, profit and loss, and cash flow data for those three quarters.

And we only have, at this stage, one quarter left in the year.

companies report on the basis of a financial year of Jan 1 to Dec 31. So by October of any financial or calendar year, as long as the sector isn't wildly seasonal, then the probability of having a surprise to annual numbers that's coming only from Q4.

So the probability of an overall surprise that a company can miss or beat earnings or revenue data,

the probability is lower than, for example, earlier in the year or even the beginning of the year.

Because now there's much more visibility on the current year.

So a company's own forecasts and forecasts from research analysts in most sectors

tend to begin focusing on next year's estimates, next year's numbers,

as soon as we enter Q4 and the Q3 earnings day is officially

behind us. It's over. Now, in our example, it just so happens with the apparel sector

that they get most of their revenue and earnings in the Q4 holiday season. So again, we have to

think about the sector that we're looking at, the stocks that

we're looking at, and how they report. What is their financial year? Are they seasonal? What is

the probability of surprise? What time of the year are we in right now? We have to use a lot of common sense to understand what's

going on. So most of the time, when we enter a calendar Q4, because most stocks have a financial

year end of December 31st, their financial year is a calendar year. When we enter Q4, it's all about

next year. It's not about this year for most stocks, especially if the stocks are not very

seasonal to the holiday season. So we have to use common sense and we have to look forwards.

So we have to use common sense and we have to look forwards. We have to look out to the following year.

So again, this is not so much a data processing issue. There are data processing elements in there, but it's more of a common sense issue.

Now, as mentioned earlier, as we move from the identification phase and we've got all of our data right, we've cleaned our data, we've got all of our formulas right,

we've made good common sense interpretations of the data, we're going to move from the

discovery or identification phase into the evidence phase.

And this is where we might start adding in extra quant.

So we might start adding in, for example, revenues and revenue growth and backwards looking quant.

And at this stage, we've seen many mistakes from retail traders here as well.

many mistakes from retail traders here as well. The most common mistake is to do this step before getting to the sector stage and trying to do it for hundreds of stocks or all 2200 plus stocks

in the spreadsheet. Next up, the most common mistake is doing it before actually cleansing the forward-looking estimates and valuation data.

So not going through the discovery phase first.

Not going through the identification phase first.

Do not do this.

Even after that stage, there are mistakes. Trying to do it for every stock in the sector.

Remember always, you should be seeking to work smart and efficiently.

For longs and shorts, we have market cap filters, so you can get to answers quickly by eliminating a lot of stocks.

And once you've done this, you can start to explore the backwards-looking quant in a separate Excel sheet.

Keep it simple, stupid.

Don't become an analyst with massive spreadsheets and end up going down major rabbit holes.

The law of diminishing marginal utility applies here.

You can find the positive and negative outliers

and everything else in between

by cleansing the data and drawing on common sense.

The rest is now evidence or exploratory work.

Another issue we see with retail traders

going through these processes is the problem

of trying to compare apples to pears.

What we're trying to do here all the time

is reflect reality and compare apples to apples.

So after cleansing data and feeling very confident

that your sector reflects reality as closely as possible,

there needs to be some discretionary fine-tuning in the next stage.

At this stage, what you've actually done is you've created your own sector to reflect reality.

And this is an excellent.

exercise that 99% of market participants will never engage in. And what you need to be very

careful of at this stage is to engage in the exercise of comparing apples to pairs instead

of comparing apples to apples. So we are seeking to reflect the reality of a sector. So we are seeking to assess market

valuation and growth rates of comparable businesses or comparable stocks in order to assess what the

market likes and what the market dislikes so we can identify positive and negative outliers

and everything else in between.

So we can't, for example, compare growth rates

like earnings growth or revenue growth rates, for example,

of, say, $200 billion companies

to the growth rates of 1 billion dollar companies. You

have to also check the contributions to the means of the largest market cap

companies and the small cap and mid cap contributions to the mean. If a sector

exhibits wildly different growth rates and valuations of mega and large cap versus mid and

small caps, you can split the sector using a market cap filter and then compare the two sectors that

you've split out based on market cap alongside each other. And you can cut and paste your findings to another sheet

and just look at mega and large cap versus small and mid cap growth rates and valuations.

In addition to that, you now have to compare similar businesses. You're going to find that there will be many

occasions when you drill down to a subsector, there will be stocks in there that seem to have

no place in the sector at all because they are in a different business area to the rest of the stocks in the sector. So remember our classification systems here.

These are NAICS and GICS classifications. They are not your classifications. You have to fix it

and create your own sector that reflects reality and compares apples to apples, not apples to pears. So let's summarize here, guys.

In the quantitative process, the identification process within trade idea generation, please a

require an analytical mind. Use common sense and have attention to detail. Do not download

spreadsheets from third-party sources and believe all the data is accurate. And do not just look at

sector data and get lazy by looking for high PE and low PE stocks,

or even high earnings growth and low earnings growth,

and then you think it's an idea.

You have to eyeball the data.

You have to clean the data, cleanse the data,

and build your own sectors to reflect reality

as closely as possible. As mentioned earlier, what you've seen

here, 99% of market participants will never, ever do this work. They don't have a systematic process

or trade idea generation like you do. They don't even

have that and they won't even do any work on data. This is where you can get a

significant edge in the market. It's a proprietary process and if you have

attention to detail with a strong interpretation of your findings, so an interpretation that requires common sense, that's going to lead to very accurate and exciting conclusions.

So make sure you have attention to detail. You work on your common sense and your interpretation. It will get better over time.

And don't be afraid to do the work. Practice, practice, practice.

Okay, guys. So this brings us to the end of this video.

Data mining and processing mistakes with the solutions.

data mining and processing mistakes with the solutions.

Next up, we're going to recap the quantitative process.